{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "7ceLmdhiLCc2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\bhara\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer,BertTokenizerFast, BertForQuestionAnswering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "8c6a9219db3e4b14be0f9af99f76fbad",
            "7caa0cbec50b431d861e8335f123a97c",
            "675e804c229e4a4bbcda754c9ad6e1d0",
            "3b1b3523f4f44e92b9057606aa1416de",
            "dc7bb69b4c5640bdb35c3de3d3984d4e",
            "55d5f382710d46b68cc3fa5edba14a3f",
            "2cd2be854d124889914f51a1c6e45c38",
            "a579eae1c7ef481f81fa022d2a5b56fd"
          ]
        },
        "id": "p1AlroecLHQw",
        "outputId": "3306ba24-df20-437e-b068-390b1ee6c047"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading (…)okenizer_config.json: 100%|██████████| 28.0/28.0 [00:00<?, ?B/s]\n",
            "Downloading (…)lve/main/config.json: 100%|██████████| 443/443 [00:00<?, ?B/s] \n",
            "Downloading (…)solve/main/vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 1.81MB/s]\n",
            "Downloading (…)/main/tokenizer.json: 100%|██████████| 466k/466k [00:00<00:00, 2.34MB/s]\n",
            "Downloading pytorch_model.bin: 100%|██████████| 1.34G/1.34G [03:04<00:00, 7.25MB/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "BertForQuestionAnswering(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 1024)\n",
              "      (token_type_embeddings): Embedding(2, 1024)\n",
              "      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-23): 24 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (qa_outputs): Linear(in_features=1024, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
        "model = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "jbLzCx8FLN4K"
      },
      "outputs": [],
      "source": [
        "def predict(context,query):\n",
        "\n",
        "  inputs = tokenizer.encode_plus(query, context, return_tensors='pt')\n",
        "\n",
        "  outputs = model(**inputs)\n",
        "  answer_start = torch.argmax(outputs[0])  # get the most likely beginning of answer with the argmax of the score\n",
        "  answer_end = torch.argmax(outputs[1]) + 1 \n",
        "\n",
        "  answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(inputs['input_ids'][0][answer_start:answer_end]))\n",
        "\n",
        "  return answer\n",
        "\n",
        "def normalize_text(s):\n",
        "  import string, re\n",
        "\n",
        "  def remove_articles(text):\n",
        "    regex = re.compile(r\"\\b(a|an|the)\\b\", re.UNICODE)\n",
        "    return re.sub(regex, \" \", text)\n",
        "\n",
        "  def white_space_fix(text):\n",
        "    return \" \".join(text.split())\n",
        "\n",
        "  def remove_punc(text):\n",
        "    exclude = set(string.punctuation)\n",
        "    return \"\".join(ch for ch in text if ch not in exclude)\n",
        "\n",
        "  def lower(text):\n",
        "    return text.lower()\n",
        "\n",
        "  return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
        "\n",
        "def compute_exact_match(prediction, truth):\n",
        "    return int(normalize_text(prediction) == normalize_text(truth))\n",
        "\n",
        "def compute_f1(prediction, truth):\n",
        "  pred_tokens = normalize_text(prediction).split()\n",
        "  truth_tokens = normalize_text(truth).split()\n",
        "  \n",
        "  if len(pred_tokens) == 0 or len(truth_tokens) == 0:\n",
        "    return int(pred_tokens == truth_tokens)\n",
        "  \n",
        "  common_tokens = set(pred_tokens) & set(truth_tokens)\n",
        "  \n",
        "  if len(common_tokens) == 0:\n",
        "    return 0\n",
        "  \n",
        "  prec = len(common_tokens) / len(pred_tokens)\n",
        "  rec = len(common_tokens) / len(truth_tokens)\n",
        "  \n",
        "  return 2 * (prec * rec) / (prec + rec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "DtMtke3JbCSR"
      },
      "outputs": [],
      "source": [
        "def give_an_answer(context,query,answer):\n",
        "\n",
        "  prediction = predict(context,query)\n",
        "  em_score = compute_exact_match(prediction, answer)\n",
        "  f1_score = compute_f1(prediction, answer)\n",
        "\n",
        "  print(f\"Question: {query}\")\n",
        "  print(f\"Prediction: {prediction}\")\n",
        "  print(f\"True Answer: {answer}\")\n",
        "  print(f\"EM: {em_score}\")\n",
        "  print(f\"F1: {f1_score}\")\n",
        "  print(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smJvu24DPWxR",
        "outputId": "adf81eaa-6b67-40a1-dfc8-1c6b881a84f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: What is the name and number of the course?\n",
            "Prediction: coen 346\n",
            "True Answer: COEN 346 Natural Language Processing\n",
            "EM: 0\n",
            "F1: 0.5714285714285715\n",
            "\n",
            "\n",
            "Question: What are some topics that are least likely to be asked in the exam?\n",
            "Prediction: word2vec and mle\n",
            "True Answer: Word2Vec and MLE\n",
            "EM: 1\n",
            "F1: 1.0\n",
            "\n",
            "\n",
            "Question: Where can I meet the professor?\n",
            "Prediction: santa clara university\n",
            "True Answer: Santa Clara University\n",
            "EM: 1\n",
            "F1: 1.0\n",
            "\n",
            "\n",
            "Question: what are some of the concepts I should study for the exam?\n",
            "Prediction: word2vec and mle\n",
            "True Answer: PLSA, Topic Modeling, RNN, NLP tasks\n",
            "EM: 0\n",
            "F1: 0\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "context = \"Hello everyone, COEN 346 course is Natural Language Processing and it is taught by Prof Yi Fang at Santa Clara University. The finals is next week and PLSA, Topic Modeling, \\\n",
        "RNN, NLP tasks are some of the important topics. Word2Vec and MLE are concepts from mid term that might not be asked in the exam.\"\n",
        "\n",
        "queries = [\"What is the name and number of the course?\",\n",
        "           \"What are some topics that are least likely to be asked in the exam?\",\n",
        "           \"Where can I meet the professor?\",\n",
        "           \"what are some of the concepts I should study for the exam?\"\n",
        "          ]\n",
        "answers = [\"COEN 346 Natural Language Processing\",\n",
        "           \"Word2Vec and MLE\",\n",
        "           \"Santa Clara University\",\n",
        "           \"PLSA, Topic Modeling, RNN, NLP tasks\"\n",
        "          ]\n",
        "\n",
        "for q,a in zip(queries,answers):\n",
        "  give_an_answer(context,q,a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7SsSHQMqU2oy",
        "outputId": "90956f87-83b6-4d22-a832-a6c23a7476b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: When did Queen found?\n",
            "Prediction: 1970\n",
            "True Answer: 1970\n",
            "EM: 1\n",
            "F1: 1.0\n",
            "\n",
            "\n",
            "Question: Who were the basic members of Queen band?\n",
            "Prediction: freddie mercury ( lead vocals, piano ), brian may ( guitar, vocals ), roger taylor ( drums, vocals ) and john deacon ( bass )\n",
            "True Answer: Freddie Mercury, Brian May, Roger Taylor and John Deacon\n",
            "EM: 0\n",
            "F1: 0.6923076923076924\n",
            "\n",
            "\n",
            "Question: What kind of band they are?\n",
            "Prediction: british rock\n",
            "True Answer: rock\n",
            "EM: 0\n",
            "F1: 0.6666666666666666\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "context = \"\"\" Queen are a British rock band formed in London in 1970. Their classic line-up was Freddie Mercury (lead vocals, piano), \n",
        "            Brian May (guitar, vocals), Roger Taylor (drums, vocals) and John Deacon (bass). Their earliest works were influenced \n",
        "            by progressive rock, hard rock and heavy metal, but the band gradually ventured into more conventional and radio-friendly \n",
        "            works by incorporating further styles, such as arena rock and pop rock. \"\"\"\n",
        "\n",
        "queries = [\"When did Queen found?\",\n",
        "           \"Who were the basic members of Queen band?\",\n",
        "           \"What kind of band they are?\"\n",
        "          ]\n",
        "answers = [\"1970\",\n",
        "           \"Freddie Mercury, Brian May, Roger Taylor and John Deacon\",\n",
        "           \"rock\"\n",
        "          ]\n",
        "\n",
        "for q,a in zip(queries,answers):\n",
        "  give_an_answer(context,q,a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rc7p-e4wj47T",
        "outputId": "165e6228-9663-4ce1-ffd2-91d342a67a00"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: Which canadian areas are safe as of now?\n",
            "Prediction: nunavut\n",
            "True Answer: Nunavut.\n",
            "EM: 1\n",
            "F1: 1.0\n",
            "\n",
            "\n",
            "Question: What is the reason behind the wildfires?\n",
            "Prediction: smoke\n",
            "True Answer: \n",
            "EM: 0\n",
            "F1: 0\n",
            "\n",
            "\n",
            "Question: Which other countries have been affected?\n",
            "Prediction: united states, and europe\n",
            "True Answer: United States and Europe\n",
            "EM: 1\n",
            "F1: 1.0\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "context = \"\"\" Beginning in March 2023 and increasing in intensity around June, Canada has been affected by an ongoing record-setting series of wildfires. As the worst wildfire season in Canadian history,[3] they have affected all Canadian provinces and territories except Nunavut.\n",
        "\n",
        "As of June 5, 2,214 fires have burned 43,000 square kilometres (10,600,000 acres).[4] As of June 6, there were 413 active wildfires, 249 of which were deemed \"out of control\".[5] Smoke emitted from the wildfires has caused air quality alerts and evacuations in Canada, the United States, and Europe \"\"\"\n",
        "\n",
        "queries = [\n",
        "           \"Which canadian areas are safe as of now?\",\n",
        "           \"What is the reason behind the wildfires?\",\n",
        "           \"Which other countries have been affected?\",\n",
        "          ]\n",
        "answers = [\n",
        "           \"Nunavut.\",\n",
        "           \"\",\n",
        "           \"United States and Europe\",\n",
        "          ]\n",
        "\n",
        "for q,a in zip(queries,answers):\n",
        "  give_an_answer(context,q,a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "of5UVn92-RbC"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2cd2be854d124889914f51a1c6e45c38": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3b1b3523f4f44e92b9057606aa1416de": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a579eae1c7ef481f81fa022d2a5b56fd",
            "placeholder": "​",
            "style": "IPY_MODEL_2cd2be854d124889914f51a1c6e45c38",
            "value": " 1.34G/1.34G [00:23&lt;00:00, 57.9MB/s]"
          }
        },
        "55d5f382710d46b68cc3fa5edba14a3f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "675e804c229e4a4bbcda754c9ad6e1d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "Downloading: 100%",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55d5f382710d46b68cc3fa5edba14a3f",
            "max": 1340675298,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dc7bb69b4c5640bdb35c3de3d3984d4e",
            "value": 1340675298
          }
        },
        "7caa0cbec50b431d861e8335f123a97c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c6a9219db3e4b14be0f9af99f76fbad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_675e804c229e4a4bbcda754c9ad6e1d0",
              "IPY_MODEL_3b1b3523f4f44e92b9057606aa1416de"
            ],
            "layout": "IPY_MODEL_7caa0cbec50b431d861e8335f123a97c"
          }
        },
        "a579eae1c7ef481f81fa022d2a5b56fd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc7bb69b4c5640bdb35c3de3d3984d4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": "initial"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
